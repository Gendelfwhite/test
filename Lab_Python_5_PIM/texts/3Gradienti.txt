В этой главе мы изучим вычислительные графы и основные особенности модуля autograd библиотеки PyTorch. В основном PyTorch используется для реализации нейронных сетей, а в них используются разнообразные и довольно сложные функции. Одна из основных причин использования PyTorch в проектах машинного обучения заключается в том, что с его помощью мы можем автоматически вычислять производные и градиенты любых функций, которые мы определяем. Выполнения программ с использованием PyTorch немного отличается от базовой логики выполнения программ на Python, эта библиотека записывает выполнение работающей программы. PyTorch запоминает последовательность операций, которые совершаются над данными, т. е. создает динамический вычислительный граф. Такой граф нужен для выполнения операции, которая называется «алгоритм обратного распространения ошибки», поскольку этот алгоритм должен в обратном направлении проходить по цепочке выполненных операций. Вычислительный граф – это запись последовательности вычислительных операций, состоящая из вершин и ребер. Вершины, иногда их еще называют узлами, – это вычислительные операции, которые необходимо выполнить, а рёбра связывают их в определённую последовательность. Вычислительные графы могут быть динамические или статические. Динамические вычислительные графы не требуют компиляции перед каждым его выполнением. В этом случае можно спокойно изменять входные данные в процессе работы. Статические вычислительные графы, с другой стороны, требуют перекомпиляции при изменении входных параметров. Они позволяют получить высокую производительность, однако закрыты для изменений. В PyTorch используются динамические вычислительные графы. На рисунке 8 приведен простой пример последовательности вычислений и визуализирован соответствующий вычислительный граф. Сначала вычисляется узел b как произведение w1 на а (b = w1 * a), и узел с как произведение w2 на a (c = w2 * a). Далее вычисляется узел d как сумма двух произведений w3 на b и w4 на c (d = (w3 * b) + (w4 * c)). И в самом конце на основе d вычисляется некоторая функция, а результат получается в узле L. Диаграмма (рис. 9) наглядно показывает весь вычисленный граф для этой последовательности вычислений. Кружочками обозначены узлы вычислительного графа, а стрелками ребра, которые связывают вычисления в определенную последовательность. 18 Рис. 8. Визуализация вычислительного графа В основе большинства современных методов машинного обучения лежит расчет градиентов и производных. Это в особенности касается нейронных сетей, в которых для настройки весовых коэффициентов используется алгоритм обратного распространения ошибки. Именно поэтому в PyTorch есть сильная нативная поддержка вычисления производных функций, которая называется автоматическим дифференцированием. Автоматическое дифференцирование позволяет эффективно проводить операцию обратного распространение ошибки в нейронных сетях. Этот метод рекурсивно использует правило дифференцирования сложной функции для вычисления градиента каждой переменной в вычислительном графе. В PyTorch инструментом для автоматического вычисления производных является модуль Autograd. Этот модуль организует запись последовательности всех операций, выполняемых над тензорами с включенным градиентом в динамическом вычислительный графе. Базовый процесс построения модели обучения нейронных сетей заключается в построении графа вычислений, вычислении функции потерь, а затем вычислении производной функции потерь по параметрам модели, с использованием таких методов, как градиентный спуск для обновления параметров. Рассмотрим использование autograd на конкретных примерах. Программный код примеров расположен по адресу: https://github.com/fgafarov1977/pytorch_nn_tutorial/blob/main/autograd.ipynb. По замыслу, в PyTorch градиенты могут быть рассчитаны только для тензоров с плавающей запятой, поэтому создадим массив чисел с плавающей запятой перед тем, как преобразовать его в тензор PyTorch с поддержкой автоматического вычисления градиентов. Для того, 19 чтобы отслеживать все операции с тензором, необходимо установить свойство requires_grad тензора в True. Это можно сделать прямо в конструкторе при создании тензора.