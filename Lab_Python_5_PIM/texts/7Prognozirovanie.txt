В этой главе мы построим рекуррентные нейронные сети на основе слоев RNN и LSTM, и применим их для решения задачи прогнозирования временных рядов. Временной ряд – это собранный в разные моменты времени статистический материал о значении каких-либо параметров исследуемого процесса. В простейшем случает временной ряд может содержать динамику только одного параметра. В настоящее время прогнозирование временных рядов является одной из наиболее популярных задач, решаемых с использованием методов машинного обучения. Прогноз будущих значений временного ряда используется для эффективного принятия решений. В качестве примеров временных рядов можно привести динамику температуру воздуха, атмосферного давления, уровня воды в каком-либо водоеме, динамику цен акций, обменные курсы валют, динамику численность населения в каком-либо городе. Программный код примера, рассмотренного в этом разделе, расположен по адресу: https://github.com/fgafarov1977/pytorch_nn_tutorial/blob/main/train_rnn.ipynb. В самом начале программы мы подключим необходимые библиотеки Python и инициализируем значения основных параметров, связанных с временным рядом и процессом обучения нейронных сетей. Естественно, подключаем библиотеку PyTorch, модуль nn, который позволит нам строить нейронные сети, добавлять необходимые слои в нейронные сети и организовать цикл обучения модели. Далее импортируем классы Dataset, DataLoader, которые позволят нам организовать процесс обучения нейронной сети на основе сгенерированного временного ряда (см. рис. 53). Далее мы инициализируем параметры, которые будут использованы как характеристики генерируемого временного ряда и процесса обучения модели. В этом примере временной ряд мы будем генерировать самостоятельно. Для простоты это будет синусоида с добавлением случайного шума. Используя переменную data_count мы указываем количество элементов временного ряда. Уровень шума, который мы добавляем к синусоиде, будем задавать с помощью переменной noise_level. Для организации обучения нам будет необходима длина скользящего окна, которая будет храниться в переменной sequenceLength. При обучении нейронной сети входные данные будем подавать пачками (батчами), поэтому нам необходимо задать размеры этих пачек. В нашем случае мы вычисляем размер пачек делением количества элементов временного ряда на длину вектора обучения. Далее мы вводим переменные, описывающие характеристики нейронных сетей. Это количество рекуррентных слоев, размерность скрытого слоя, шаг обучения и количество эпох обучения (см. рис. 53). 56 Рис. 53. Подключение необходимых библиотек и инициализация параметров В качестве временного ряда будет выступать простая синусоида с добавлением случайного шума (см. рис. 54). Уровень шума задается переменной noise_level, которая была инициализирована в самом начале программы. Временные ряды зависят от времени, поэтому сначала создаем переменную t, в которой будут равномерно записаны числа от 0 до 100. Количество временных шагов будет равно значению переменной data_count. Мы будем создавать две выборки: обучающую и тестовую. На обучающей выборке мы будет обучать нейросеть, а на тестовой выборке мы оценим качество нейронной сети. Эти выборки создаются с помощь суммирования результата функции torch.sin – которая генерирует синусоиду, и функции torch.randn – которая генерирует тензор со случайными значениям. Предварительно, результат, выдаваемый этим методом, мы умножаем на значение переменной noise_level, которая описывает уровень шума. Таким образом, изменяя значение этой переменной, мы может делать наш временной ряд более зашумленным или менее зашумленным. Для того, чтобы посмотреть, как выглядит наш временной ряд, мы можем построить его в виде графика. Вы можете попробовать поменять значение переменной noise_level, для того чтобы посмотреть, как выглядит временной ряд для различного уровня добавляемого шума. Рис. 54. Генерация данных для обучения нейронных сетей 57 Тестовая выборка, которая не будет участвовать в процессе обучения моделей, а будет применена на этапе оценки качества модели, генерируется аналогично (см. рис. 55). Рис. 55. График обучающей выборки Используем метод скользящего окна при формировании набора данных для обучения модели. Для построения скользящего окна берется некоторый отрезок временного ряда длиной sequenceLength, который и будет представлять собой входной вектор. Значением желаемого выхода в примере будет следующее по порядку значение. Затем «скользящее окно» сдвигается на одну позицию в направлении возрастания времени, и процесс формирования следующей пары обучающей выборки повторяется. Для организации процесса обучения моделей нейронных сетей удобно использовать классы, наследуемые от класса DataSet библиотеки PyTorch. Для этого создадим класс, который назовем DatasetSin, и в качестве родительского класса укажем класс DataSet. В этом классе нам необходимо создать три метода. Первый метод – это конструктор, в него мы передаем весь временной ряд и также переменную, sequenceLength, которая задает длину скользящего окна. Эти данные будут хранится в виде внутренних переменных класса. Следующая функция, которую мы должны также обязательно добавить в этот класс – это функция len, возвращающая общее количество обучающих векторов (см. рис. 56). Получение отдельной обучающей пары реализовано в методе getitem. Здесь в переменную data_sequence записывается отрезок данных длиной sequenceLength, а в переменную next_value записываем следующее значение временного ряда. Значения этих переменных образуют обучающую пару и возвращаются из этого метода. (см. рис. 56). 58 Рис. 56. Описание класса DatasetSin Далее мы создаем объект класса DatasetSin и сохраняем его в переменную datasetTrain. В конструкторе передаем наш PyTorch тензор, содержащий данные обучающей выборки. Далее, на основе этого датасета мы создаем объект класса DataLoader, который позволит нам организовать процесс итеративного обучения модели нейронной сети. Мы можем проверить, как работает этот объект, организовав циклическую итерацию через конструкцию for. Здесь входной вектор будет возвращаться в виде тензора x_data, а соответствующие им целевые значения в виде вектора y_data. Мы можем вывести эти значения на консоль, используя стандартный метод print (см. рис. 57). Рис. 57. Подготовка данных 59 Здесь мы также создаем аналогичные объекты и для тестового набора данных. Результаты вывода на консоль значений тензоров x_data и y_data показаны на рисунке 58. Рис. 58. Вывод на консоль Далее необходимо создать класс, описывающие нейронные сети. Создадим два вида рекуррентных нейронных сетей. Первая сеть будет основана на классических рекуррентных нейронах, слои которых будет добавляться как RNN слои из модуля nn Pytorch, а вторая нейронная сеть будет LSTM нейронной сетью, и для ее создания используем LSTM слой библиотеки PyTorch.